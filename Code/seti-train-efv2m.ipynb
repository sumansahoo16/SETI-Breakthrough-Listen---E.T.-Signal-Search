{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q efficientnet >> /dev/null\n\nimport random, os\nimport pandas as pd, numpy as np\nimport matplotlib.pyplot as plt\nfrom kaggle_datasets import KaggleDatasets\nimport tensorflow_hub as tfhub\nimport tensorflow as tf, math\nimport tensorflow_addons as tfa\nimport efficientnet.tfkeras as efn\nimport tensorflow.keras.backend as K\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import roc_auc_score","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-16T09:02:54.856899Z","iopub.execute_input":"2021-08-16T09:02:54.857280Z","iopub.status.idle":"2021-08-16T09:03:10.303826Z","shell.execute_reply.started":"2021-08-16T09:02:54.857200Z","shell.execute_reply":"2021-08-16T09:03:10.302856Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"DEVICE = \"TPU\" #or \"GPU\"\n\nSEED = 16\n\ntrain_fold = 0\n\nMODEL_GCS_PATH = 'gs://kds-a4518d8bb2ac917f269f913bed4066c2943089632d96cf03f86b5699/tfhub_models/efficientnetv2-m-21k-ft1k/feature_vector'\n\nFOLDS = 5\n\nimg_size = (273 * 3, 256 * 2)\nbatch_size = 16\nEPOCHS = 20\nwarmup = 2\n\nlearning_rate_base =  8e-4\n\n\nEFF_NET = 1\nweights = 'noisy-student' #'noisy-student' 'imagenet'\n\nupsample = False\n\n\ndef seed_everything(seed = 42):\n    random.seed(seed)\n    np.random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    tf.random.set_seed(seed)\n    \nseed_everything(SEED)\n\n\nif DEVICE == \"TPU\":\n    print(\"connecting to TPU...\")\n    try:\n        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n        print('Running on TPU ', tpu.master())\n    except ValueError:\n        print(\"Could not connect to TPU\")\n        tpu = None\n\n    if tpu:\n        try:\n            print(\"initializing  TPU ...\")\n            tf.config.experimental_connect_to_cluster(tpu)\n            tf.tpu.experimental.initialize_tpu_system(tpu)\n            strategy = tf.distribute.experimental.TPUStrategy(tpu)\n            print(\"TPU initialized\")\n        except _:\n            print(\"failed to initialize TPU\")\n    else:\n        DEVICE = \"GPU\"\n\nif DEVICE != \"TPU\":\n    print(\"Using default strategy for CPU and single GPU\")\n    strategy = tf.distribute.get_strategy()\n\nif DEVICE == \"GPU\":\n    print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n    \n\nAUTO     = tf.data.experimental.AUTOTUNE\nREPLICAS = strategy.num_replicas_in_sync\nprint(f'REPLICAS: {REPLICAS}')","metadata":{"execution":{"iopub.status.busy":"2021-08-16T09:03:10.306521Z","iopub.execute_input":"2021-08-16T09:03:10.306843Z","iopub.status.idle":"2021-08-16T09:03:15.795375Z","shell.execute_reply.started":"2021-08-16T09:03:10.306816Z","shell.execute_reply":"2021-08-16T09:03:15.794627Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"connecting to TPU...\nRunning on TPU  grpc://10.0.0.2:8470\ninitializing  TPU ...\nTPU initialized\nREPLICAS: 8\n","output_type":"stream"}]},{"cell_type":"code","source":"GCS_PATH = KaggleDatasets().get_gcs_path('seti-new-tfrecords')\nprint(GCS_PATH)\nfiles_all = np.sort(np.array(tf.io.gfile.glob(GCS_PATH + '/train_*.tfrec')))\nfiles_all","metadata":{"execution":{"iopub.status.busy":"2021-08-16T09:03:15.796950Z","iopub.execute_input":"2021-08-16T09:03:15.797233Z","iopub.status.idle":"2021-08-16T09:03:16.220107Z","shell.execute_reply.started":"2021-08-16T09:03:15.797208Z","shell.execute_reply":"2021-08-16T09:03:16.219139Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"gs://kds-9b9c4ddce7c3e38519cd32b3e426df8ac735bd0c9c95edb2aaed094f\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"array(['gs://kds-9b9c4ddce7c3e38519cd32b3e426df8ac735bd0c9c95edb2aaed094f/train_0_3000.tfrec',\n       'gs://kds-9b9c4ddce7c3e38519cd32b3e426df8ac735bd0c9c95edb2aaed094f/train_10_3000.tfrec',\n       'gs://kds-9b9c4ddce7c3e38519cd32b3e426df8ac735bd0c9c95edb2aaed094f/train_11_3000.tfrec',\n       'gs://kds-9b9c4ddce7c3e38519cd32b3e426df8ac735bd0c9c95edb2aaed094f/train_12_3000.tfrec',\n       'gs://kds-9b9c4ddce7c3e38519cd32b3e426df8ac735bd0c9c95edb2aaed094f/train_13_3000.tfrec',\n       'gs://kds-9b9c4ddce7c3e38519cd32b3e426df8ac735bd0c9c95edb2aaed094f/train_14_3000.tfrec',\n       'gs://kds-9b9c4ddce7c3e38519cd32b3e426df8ac735bd0c9c95edb2aaed094f/train_15_3000.tfrec',\n       'gs://kds-9b9c4ddce7c3e38519cd32b3e426df8ac735bd0c9c95edb2aaed094f/train_16_3000.tfrec',\n       'gs://kds-9b9c4ddce7c3e38519cd32b3e426df8ac735bd0c9c95edb2aaed094f/train_17_3000.tfrec',\n       'gs://kds-9b9c4ddce7c3e38519cd32b3e426df8ac735bd0c9c95edb2aaed094f/train_18_3000.tfrec',\n       'gs://kds-9b9c4ddce7c3e38519cd32b3e426df8ac735bd0c9c95edb2aaed094f/train_19_3000.tfrec',\n       'gs://kds-9b9c4ddce7c3e38519cd32b3e426df8ac735bd0c9c95edb2aaed094f/train_1_3000.tfrec',\n       'gs://kds-9b9c4ddce7c3e38519cd32b3e426df8ac735bd0c9c95edb2aaed094f/train_2_3000.tfrec',\n       'gs://kds-9b9c4ddce7c3e38519cd32b3e426df8ac735bd0c9c95edb2aaed094f/train_3_3000.tfrec',\n       'gs://kds-9b9c4ddce7c3e38519cd32b3e426df8ac735bd0c9c95edb2aaed094f/train_4_3000.tfrec',\n       'gs://kds-9b9c4ddce7c3e38519cd32b3e426df8ac735bd0c9c95edb2aaed094f/train_5_3000.tfrec',\n       'gs://kds-9b9c4ddce7c3e38519cd32b3e426df8ac735bd0c9c95edb2aaed094f/train_6_3000.tfrec',\n       'gs://kds-9b9c4ddce7c3e38519cd32b3e426df8ac735bd0c9c95edb2aaed094f/train_7_3000.tfrec',\n       'gs://kds-9b9c4ddce7c3e38519cd32b3e426df8ac735bd0c9c95edb2aaed094f/train_8_3000.tfrec',\n       'gs://kds-9b9c4ddce7c3e38519cd32b3e426df8ac735bd0c9c95edb2aaed094f/train_9_3000.tfrec'],\n      dtype='<U85')"},"metadata":{}}]},{"cell_type":"code","source":"def mixup(image, label):\n    # input image - is a batch of images of size [n,dim,dim,3] not a single image of [dim,dim,3]\n    # output - a batch of images with mixup applied\n    \n    imgs = []; labs = []\n    for j in range(batch_size * REPLICAS):\n        # CHOOSE RANDOM\n        k = tf.cast( tf.random.uniform([], 0, batch_size), tf.int32)\n        p = tf.random.uniform([], 0.0, 1.0)\n        \n        # MAKE MIXUP IMAGE\n        img1 = image[j,]\n        img2 = image[k,]\n        \n        lab1 =  tf.cast(label[j], tf.float32)\n        lab2 =  tf.cast(label[k], tf.float32)\n        \n        imgs.append((1-p)*img1 + p*img2)\n        labs.append((1-p)*lab1 + p*lab2)\n            \n    # RESHAPE HACK SO TPU COMPILER KNOWS SHAPE OF OUTPUT TENSOR (maybe use Python typing instead?)\n    image2 = tf.reshape(tf.stack(imgs),(batch_size * REPLICAS, img_size[0], img_size[1], 3))\n    label2 = tf.reshape(tf.stack(labs),(batch_size * REPLICAS, 1))\n    \n    return image2,label2\n\ndef prepare_image(img, augment=True, dim=256):    \n    img = tf.io.decode_raw(img, tf.float16)\n    img = tf.reshape(img, [273, 256, 3])\n    img = tf.cast(img, tf.float32)\n    \n    # Already pre-processed \n    #img = tf.clip_by_value(img, clip_value_min=-6.0, clip_value_max=6.0)\n    #img = img / 3.0\n    \n    if augment and  tf.random.uniform([]) > 0.75:\n        \n        channels = tf.unstack(img, axis=-1)\n        \n        if tf.random.uniform([]) > 0.5:\n            channels[0] = tf.reverse(channels[0], [0])\n        if tf.random.uniform([]) > 0.5:\n            channels[0] = tf.reverse(channels[0], [1])\n            \n        if tf.random.uniform([]) > 0.5:\n            channels[1] = tf.reverse(channels[1], [0])\n        if tf.random.uniform([]) > 0.5:\n            channels[1] = tf.reverse(channels[1], [1])\n            \n        if tf.random.uniform([]) > 0.5:\n            channels[2] = tf.reverse(channels[2], [0])\n        if tf.random.uniform([]) > 0.5:\n            channels[2] = tf.reverse(channels[2], [1])\n            \n        channels = tf.random.shuffle(channels)\n        #img = tf.stack(channels, axis = -1)\n        img = tf.stack([channels[0], channels[1], channels[2]], axis = -1)\n    \n    img = tf.unstack(img, axis = 2)\n    img = tf.concat(img, axis = 0)\n    img = tf.expand_dims(img, 2)\n    img = tf.image.grayscale_to_rgb(img)\n    \n    img = tf.image.resize(img, [img_size[0], img_size[1]])\n    \n    if augment:\n        img = tf.image.random_flip_left_right(img)\n        img = tf.image.random_flip_up_down(img)\n               \n    #img = tf.reshape(img, [dim[0], dim[1], 3])\n            \n    return img\n\ndef count_data_items(filenames):\n    n = [int(filename.split('_')[-1].split('.')[0]) for filename in filenames]\n    return np.sum(n)\n\n\ndef read_labeled_tfrecord(example):\n    tfrec_format = {\n        'signal'   : tf.io.FixedLenFeature([], tf.string),\n        'id'       : tf.io.FixedLenFeature([], tf.string),\n        'target'   : tf.io.FixedLenFeature([], tf.float32),\n    }           \n    example = tf.io.parse_single_example(example, tfrec_format)\n    return example['signal'], example['target']\n\n\ndef get_dataset(files, augment = False, shuffle = False, repeat = False, \n                labeled=True, return_image_names=True, batch_size=16, dim=256):\n    \n    ds = tf.data.TFRecordDataset(files, num_parallel_reads=AUTO)\n    ds = ds.cache()\n    \n    if repeat:\n        ds = ds.repeat()\n    \n    if shuffle: \n        ds = ds.shuffle(1024*8)\n        opt = tf.data.Options()\n        opt.experimental_deterministic = False\n        ds = ds.with_options(opt)\n        \n    if labeled: \n        ds = ds.map(read_labeled_tfrecord, num_parallel_calls=AUTO)\n    else:\n        ds = ds.map(lambda example: read_unlabeled_tfrecord(example, return_image_names), \n                    num_parallel_calls=AUTO)      \n    \n    ds = ds.map(lambda img, imgname_or_label: (prepare_image(img, augment=augment, dim=dim), \n                                               imgname_or_label), \n                num_parallel_calls=AUTO)\n    \n    ds = ds.batch(batch_size * REPLICAS)\n    ds = ds.prefetch(AUTO)\n    \n    if augment:\n        ds = ds.map(mixup, num_parallel_calls = AUTO)\n        \n    if augment and tf.random.uniform([]) > 0.5:\n        ds = ds.map(lambda img, y: (tfa.image.random_cutout(img, mask_size = (200, 128)), y))\n                    \n    if augment and tf.random.uniform([]) > 0.75:\n        ds = ds.map(lambda img, y: (tfa.image.random_cutout(img, mask_size = (200, 128)), y))\n        \n    return ds\n\nclass cosine_annealing_warmup(tf.keras.optimizers.schedules.LearningRateSchedule):\n    def __init__(self, learning_rate_base, num_warmup_steps, num_training_steps):\n        self.lr = learning_rate_base\n        self.ws = num_warmup_steps\n        self.ts = num_training_steps\n\n    def __call__(self, step):\n        return tf.where(step <= self.ws, self.lr * tf.cast(step, tf.float32) / tf.cast(self.ws, tf.float32), \n            self.lr*0.5*(1+tf.cos(math.pi*0.5*2.0*tf.cast(step - self.ws, tf.float32) / tf.cast(self.ws - self.ts, tf.float32))))\n\n\nEFNS = [efn.EfficientNetB0, efn.EfficientNetB1, efn.EfficientNetB2, efn.EfficientNetB3, \n        efn.EfficientNetB4, efn.EfficientNetB5, efn.EfficientNetB6]\n\ndef build_model(dim=128, ef=0, steps_per_epoch=0):\n    \n    inp = tf.keras.layers.Input(shape=(dim[0],dim[1],3))\n    \n    base = EFNS[ef](input_shape=(dim[0],dim[1],3), weights=weights,include_top=False)\n    #base = tf.keras.applications.resnet_v2.ResNet50V2(include_top = False)\n    x = base(inp)\n    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n\n    x = tf.keras.layers.Dropout(0.5)(x)\n    x = tf.keras.layers.Dense(1,activation='sigmoid')(x)\n    \n    model = tf.keras.Model(inputs=inp,outputs=x)\n    \n    #model = tf.keras.Sequential([\n    #        tf.keras.layers.InputLayer(input_shape=[dim[0],dim[1],3]),\n    #        tfhub.KerasLayer(MODEL_GCS_PATH , trainable=True),\n    #        tf.keras.layers.Dropout(rate=0.5),\n    #        tf.keras.layers.Dense(1,activation='sigmoid')\n    #    ])\n    \n    #caw = cosine_annealing_warmup(learning_rate_base = learning_rate_base,\n    #                              num_warmup_steps = EPOCHS * steps_per_epoch,\n    #                              num_training_steps = int(warmup *  steps_per_epoch))\n    \n    opt = tf.keras.optimizers.Adam()\n    loss = tf.keras.losses.BinaryCrossentropy(label_smoothing=0.05) #label_smoothing=0.05\n    model.compile(optimizer=opt,loss=loss,metrics=['AUC'])\n    return model\n\ndef get_lr_callback(batch_size=8):\n    lr_start   = 5e-6\n    lr_max     = 5-4\n    lr_min     = 5e-6\n    lr_ramp_ep = 4\n    lr_sus_ep  = 0\n    lr_decay   = 0.8\n   \n    def lrfn(epoch):\n        if epoch < lr_ramp_ep:\n            lr = (lr_max - lr_start) / lr_ramp_ep * epoch + lr_start\n            \n        elif epoch < lr_ramp_ep + lr_sus_ep:\n            lr = lr_max\n            \n        else:\n            lr = (lr_max - lr_min) * lr_decay**(epoch - lr_ramp_ep - lr_sus_ep) + lr_min\n            \n        return lr\n\n    lr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=False)\n    return lr_callback","metadata":{"execution":{"iopub.status.busy":"2021-08-16T09:03:16.222062Z","iopub.execute_input":"2021-08-16T09:03:16.222466Z","iopub.status.idle":"2021-08-16T09:03:16.434129Z","shell.execute_reply.started":"2021-08-16T09:03:16.222424Z","shell.execute_reply":"2021-08-16T09:03:16.432944Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# USE VERBOSE=0 for silent, VERBOSE=1 for interactive, VERBOSE=2 for commit\nVERBOSE = 1\nDISPLAY_PLOT = True\n\nauc_ = []\n\nskf = KFold(n_splits=FOLDS,shuffle=True,random_state=SEED)\nfor fold,(idxT,idxV) in enumerate(skf.split(np.arange(len(files_all)))):\n    \n    if fold != train_fold:\n        continue\n    \n    # DISPLAY FOLD INFO\n    if DEVICE=='TPU':\n        if tpu: tf.tpu.experimental.initialize_tpu_system(tpu)\n    print('#'*25); print('#### FOLD',fold+1)\n    \n    # CREATE TRAIN AND VALIDATION SUBSETS\n    #if add_old_one:\n    #    files_train = tf.io.gfile.glob([files_all[x] for x in idxT] + [GCS_PATH + '/old_one_10012.tfrec'])\n    #else:\n    #    files_train = tf.io.gfile.glob([files_all[x] for x in idxT])\n    files_train = tf.io.gfile.glob([files_all[x] for x in idxT])\n    np.random.shuffle(files_train); print('#'*25)\n    files_valid = tf.io.gfile.glob([files_all[x] for x in idxV])\n    \n    steps_per_epoch=count_data_items(files_train)/batch_size//REPLICAS\n    \n    # BUILD MODEL\n    K.clear_session()\n    with strategy.scope():\n        model = build_model(dim=img_size ,ef=EFF_NET, steps_per_epoch = steps_per_epoch)\n        #model.load_weights('../input/seti-pretrain-b3-896-896-0208/fold-0.h5')\n        \n    # SAVE BEST MODEL EACH FOLD\n    sv = tf.keras.callbacks.ModelCheckpoint(\n        'fold-%i.h5'%fold, monitor='val_auc', verbose=0, save_best_only=True,\n         save_weights_only=True, mode='max', save_freq='epoch')\n   \n    # TRAIN\n    history = model.fit(\n        get_dataset(files_train, augment=True, shuffle=True, repeat=True,\n                dim=img_size, batch_size = batch_size), \n        \n        epochs=EPOCHS, callbacks = [sv, get_lr_callback(batch_size)], #get_lr_callback(batch_size)\n        steps_per_epoch=count_data_items(files_train)/batch_size//REPLICAS,\n        validation_data=get_dataset(files_valid,augment=False,shuffle=False,\n        repeat=False,dim=img_size), \n        verbose=VERBOSE)\n    \n\n    #model.load_weights('fold-%i.h5'%fold)\n    print()\n    print('--------------- MAX AUC :- ', np.max(history.history['val_auc']))\n    print()\n    auc_.append(np.max(history.history['val_auc']))\n    \n    # PLOT TRAINING\n    if DISPLAY_PLOT:\n        plt.figure(figsize=(15,5))\n        plt.plot(np.arange(EPOCHS),history.history['auc'],'-o',label='Train AUC',color='#ff7f0e')\n        plt.plot(np.arange(EPOCHS),history.history['val_auc'],'-o',label='Val AUC',color='#1f77b4')\n        x = np.argmax( history.history['val_auc'] ); y = np.max( history.history['val_auc'] )\n        xdist = plt.xlim()[1] - plt.xlim()[0]; ydist = plt.ylim()[1] - plt.ylim()[0]\n        plt.scatter(x,y,s=300,color='#1f77b4')\n        plt.ylabel('AUC',size=14); plt.xlabel('Epoch',size=14)\n        plt.legend(loc=2)\n        plt2 = plt.gca().twinx()\n        plt2.plot(np.arange(EPOCHS),history.history['loss'],'-o',label='Train Loss',color='#2ca02c')\n        plt2.plot(np.arange(EPOCHS),history.history['val_loss'],'-o',label='Val Loss',color='#d62728')\n        x = np.argmin( history.history['val_loss'] ); y = np.min( history.history['val_loss'] )\n        ydist = plt.ylim()[1] - plt.ylim()[0]\n        plt.ylabel('Loss',size=14)\n        plt.legend(loc=3)\n        plt.show()  ","metadata":{"execution":{"iopub.status.busy":"2021-08-16T09:03:16.435686Z","iopub.execute_input":"2021-08-16T09:03:16.436091Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"#########################\n#### FOLD 1\n#########################\nDownloading data from https://github.com/qubvel/efficientnet/releases/download/v0.0.1/efficientnet-b1_noisy-student_notop.h5\n27017216/27010080 [==============================] - 0s 0us/step\nEpoch 1/20\n375/375 [==============================] - 655s 2s/step - loss: 0.5267 - auc: 0.5064 - val_loss: 0.3819 - val_auc: 0.5168\nEpoch 2/20\n375/375 [==============================] - 564s 2s/step - loss: 0.3671 - auc: 0.5106 - val_loss: 0.3399 - val_auc: 0.6681\nEpoch 3/20\n375/375 [==============================] - 566s 2s/step - loss: 0.3487 - auc: 0.5934 - val_loss: 0.2810 - val_auc: 0.8091\nEpoch 4/20\n375/375 [==============================] - 567s 2s/step - loss: 0.3390 - auc: 0.6517 - val_loss: 0.2743 - val_auc: 0.8245\nEpoch 5/20\n375/375 [==============================] - 566s 2s/step - loss: 0.3215 - auc: 0.6708 - val_loss: 0.2809 - val_auc: 0.8191\nEpoch 6/20\n375/375 [==============================] - 564s 2s/step - loss: 0.3221 - auc: 0.6756 - val_loss: 0.2808 - val_auc: 0.8237\nEpoch 7/20\n375/375 [==============================] - 566s 2s/step - loss: 0.3199 - auc: 0.6976 - val_loss: 0.2627 - val_auc: 0.8386\nEpoch 8/20\n375/375 [==============================] - 567s 2s/step - loss: 0.3102 - auc: 0.7037 - val_loss: 0.2587 - val_auc: 0.8439\nEpoch 9/20\n375/375 [==============================] - 566s 2s/step - loss: 0.3080 - auc: 0.7024 - val_loss: 0.2618 - val_auc: 0.8500\nEpoch 10/20\n375/375 [==============================] - 566s 2s/step - loss: 0.3139 - auc: 0.7131 - val_loss: 0.2644 - val_auc: 0.8529\nEpoch 11/20\n375/375 [==============================] - 569s 2s/step - loss: 0.3098 - auc: 0.7353 - val_loss: 0.2621 - val_auc: 0.8562\nEpoch 12/20\n375/375 [==============================] - 566s 2s/step - loss: 0.3107 - auc: 0.7143 - val_loss: 0.2514 - val_auc: 0.8580\nEpoch 13/20\n375/375 [==============================] - 564s 2s/step - loss: 0.3081 - auc: 0.7403 - val_loss: 0.2510 - val_auc: 0.8583\nEpoch 14/20\n375/375 [==============================] - 568s 2s/step - loss: 0.3102 - auc: 0.7170 - val_loss: 0.2478 - val_auc: 0.8621\nEpoch 15/20\n375/375 [==============================] - 567s 2s/step - loss: 0.3035 - auc: 0.7294 - val_loss: 0.2476 - val_auc: 0.8639\nEpoch 16/20\n375/375 [==============================] - 567s 2s/step - loss: 0.3071 - auc: 0.7294 - val_loss: 0.2482 - val_auc: 0.8643\nEpoch 17/20\n375/375 [==============================] - 566s 2s/step - loss: 0.3015 - auc: 0.7429 - val_loss: 0.2479 - val_auc: 0.8659\nEpoch 18/20\n375/375 [==============================] - 566s 2s/step - loss: 0.3024 - auc: 0.7298 - val_loss: 0.2464 - val_auc: 0.8638\nEpoch 19/20\n 39/375 [==>...........................] - ETA: 7:48 - loss: 0.3186 - auc: 0.7462","output_type":"stream"}]}]}